ğŸ¤– Lib-Pal: RAG-Based Chatbot for Document-Aware Q&A

Lib-Pal is a Retrieval-Augmented Generation (RAG) based chatbot designed for libraries, researchers, and academic users. It allows users to upload local documents and ask natural language questions, receiving accurate, source-grounded answers powered by vector search and Google Gemini API.

This project focuses on local document intelligence, data privacy, and explainable responses with citationsâ€”making it suitable for academic libraries and research environments.

ğŸš€ Features

ğŸ“„ Upload PDF, DOCX, and TXT documents

ğŸ” Semantic search using vector embeddings (FAISS)

ğŸ’¬ Conversational Q&A over uploaded documents

ğŸ“š Source citations with relevance scores

ğŸ§  Powered by Google Gemini LLM

ğŸ–¥ï¸ Simple and interactive Streamlit UI

ğŸ” API key via environment variables (secure)

â™»ï¸ Reset knowledge base and chat history anytime

ğŸ—ï¸ System Architecture (RAG Workflow)

Document Upload (User)

Text Extraction & Chunking

Embedding Generation (Sentence Transformers)

Vector Storage (FAISS)

Query Embedding

Top-K Similarity Retrieval

Context Injection

Answer Generation (Gemini API)

Response + Source Display

ğŸ§© Project Structure
â”œâ”€â”€ app.py                     # Main Streamlit application
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ document_processor.py  # PDF, DOCX, TXT parsing & chunking
â”‚   â”œâ”€â”€ vector_store.py        # FAISS vector store manager
â”‚   â”œâ”€â”€ rag_pipeline.py        # Retrieval + generation logic
â”‚   â””â”€â”€ gemini_client.py       # Google Gemini API interface
â”œâ”€â”€ .env                       # Environment variables (not committed)
â””â”€â”€ README.md

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/your-username/lib-pal-rag-chatbot.git
cd lib-pal-rag-chatbot

2ï¸âƒ£ Create Virtual Environment (Recommended)
python -m venv venv
source venv/bin/activate   # Linux / Mac
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

ğŸ”‘ Environment Configuration

Create a .env file in the root directory:

GEMINI_API_KEY=your_google_gemini_api_key_here


âš ï¸ The application will not process documents without a valid API key.

â–¶ï¸ Run the Application
streamlit run app.py


Then open your browser at:

http://localhost:8501

ğŸ§ª Supported File Formats

âœ… PDF (.pdf)

âœ… Word (.docx)

âœ… Plain Text (.txt)

ğŸ“Š Output & Transparency

Answers are grounded only in uploaded documents

Each response includes:

Retrieved document chunks

Relevance scores

Reduces hallucinations compared to standalone LLMs

ğŸ¯ Use Cases

ğŸ“š Academic & University Libraries

ğŸ” Research Assistance & Literature Review

ğŸ›ï¸ Institutional Repositories

ğŸ“ Teaching & Information Literacy

ğŸ§  Local Knowledge Bases (Privacy-Preserving)

ğŸ› ï¸ Technologies Used

Streamlit â€“ UI framework

FAISS â€“ Vector similarity search

Sentence Transformers â€“ Text embeddings

Google Gemini API â€“ Large Language Model

Python-dotenv â€“ Environment management

ğŸ‘¨â€ğŸ’» Developer

Pawan Pal
Research Scholar (Library & Information Science)
University of Calcutta
Assistant, Central Library, Assam University (Silchar)

Developed with a vision for future-ready, AI-powered academic libraries.

ğŸ“œ License

This project is intended for educational and research purposes.
You may modify and extend it with proper attribution.
